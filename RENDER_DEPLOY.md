# ğŸš€ Guide de DÃ©ploiement Render.com

## Configuration complÃ¨te prÃªte pour Render

Tous les fichiers sont optimisÃ©s pour un dÃ©ploiement sur Render.com :

âœ… `render.yaml` - Configuration Blueprint Render  
âœ… `gunicorn_config.py` - Serveur de production optimisÃ©  
âœ… `requirements.txt` - Toutes les dÃ©pendances  
âœ… `build.sh` - Script de build automatique  
âœ… `start-render.sh` - Script de dÃ©marrage robuste  

---

## ğŸ“‹ Ã‰tapes de dÃ©ploiement

### 1. Aller sur Render.com

ğŸ‘‰ [render.com](https://render.com)

- Cliquez sur **"Get Started"**
- Connectez-vous avec votre compte GitHub

### 2. CrÃ©er le Web Service Backend

1. Dans le dashboard : **"New +"** â†’ **"Web Service"**

2. Autorisez Render Ã  accÃ©der Ã  GitHub (si premiÃ¨re fois)

3. SÃ©lectionnez le repository : **`light667/ai-recommender`**

4. Configuration du service :

   **Basic Settings:**
   ```
   Name: ai-recommender-backend
   Region: Frankfurt (ou le plus proche de vous)
   Branch: main
   Root Directory: (laisser vide)
   Runtime: Python 3
   ```

   **Build & Deploy:**
   ```
   Build Command:
   pip install -r requirements.txt && cd backend && python recommender.py && cd ..
   
   Start Command:
   gunicorn --bind 0.0.0.0:$PORT --config backend/gunicorn_config.py backend.app:app
   ```

   **Instance Type:**
   ```
   Free
   ```

   **Advanced (optionnel):**
   - Health Check Path: `/`
   - Auto-Deploy: Yes (recommandÃ©)

5. Cliquez sur **"Create Web Service"**

### 3. Attendre le dÃ©ploiement

â±ï¸ **Temps estimÃ© : 5-10 minutes**

Le processus :
1. âš™ï¸ Installation des dÃ©pendances (2-3 min)
2. ğŸ§  EntraÃ®nement du modÃ¨le ML (3-5 min)
3. ğŸš€ DÃ©marrage du serveur (30 sec)

Vous pouvez suivre les logs en temps rÃ©el dans l'onglet **"Logs"**.

### 4. RÃ©cupÃ©rer l'URL

Une fois dÃ©ployÃ© (statut vert âœ…), vous verrez :

```
https://ai-recommender-backend-XXXX.onrender.com
```

**Testez l'API :**
```bash
curl https://ai-recommender-backend-XXXX.onrender.com/api/stats
```

---

## ğŸ¯ Configuration optimale appliquÃ©e

### âœ… Port dynamique
```python
port = os.getenv("PORT", "5000")  # Render dÃ©finit automatiquement PORT
```

### âœ… Workers optimisÃ©s
```python
workers = 2  # Parfait pour le plan gratuit
timeout = 300  # 5 minutes pour les requÃªtes longues
```

### âœ… Health checks
```python
@app.route('/')
def home():
    return jsonify({'status': 'healthy'})
```

### âœ… Logging
```python
accesslog = "-"  # Logs dans stdout (visible dans Render)
errorlog = "-"
loglevel = "info"
```

---

## ğŸ”§ Variables d'environnement (dÃ©jÃ  configurÃ©es)

Render dÃ©finira automatiquement :

| Variable | Valeur | Description |
|----------|--------|-------------|
| `PORT` | `10000` | Port assignÃ© par Render |
| `PYTHON_VERSION` | `3.11.0` | Version Python |
| `FLASK_ENV` | `production` | Mode production |
| `WORKERS` | `2` | Nombre de workers Gunicorn |

---

## ğŸ“Š Monitoring

### Voir les logs en temps rÃ©el

1. Dans votre service Render
2. Onglet **"Logs"**
3. Logs de build + runtime

### MÃ©triques

- **CPU Usage** : visible dans l'onglet "Metrics"
- **Memory** : surveillÃ© automatiquement
- **Requests** : compteur de requÃªtes

---

## âš ï¸ Limitations du plan gratuit

| Limite | Valeur |
|--------|--------|
| RAM | 512 MB |
| CPU | PartagÃ© |
| Veille | AprÃ¨s 15 min inactivitÃ© |
| Cold start | 30-60 secondes |
| Heures/mois | 750h gratuit |

**ğŸ’¡ Solutions :**
- Le modÃ¨le est sauvegardÃ© (pas besoin de rÃ©entraÃ®ner)
- Cold start uniquement au premier accÃ¨s
- Pour always-on : upgrade Ã  $7/mois

---

## ğŸ› DÃ©pannage

### Erreur "Build failed"
```bash
# VÃ©rifier les logs de build
# Souvent : problÃ¨me de dÃ©pendances

# Solution : vÃ©rifier requirements.txt
pip install -r requirements.txt  # test local
```

### Erreur "Application failed to respond"
```bash
# VÃ©rifier que le port est bien dynamique
# Dans gunicorn_config.py :
bind = f"0.0.0.0:{os.getenv('PORT', '5000')}"
```

### Erreur "Out of memory"
```bash
# Le modÃ¨le est trop gros pour 512MB
# Solution : optimiser le modÃ¨le ou upgrade plan
```

### Cold start trop long
```bash
# Normal la premiÃ¨re fois (entraÃ®nement)
# Ensuite le modÃ¨le est en cache
# Pour Ã©viter : utiliser un cron job pour ping
```

---

## ğŸ”„ Mises Ã  jour

Render redÃ©ploie automatiquement Ã  chaque push sur `main` :

```bash
git add .
git commit -m "Update API"
git push
```

Ou manuellement dans Render : bouton **"Manual Deploy"**

---

## ğŸŒ Ã‰tape suivante : Frontend

Une fois le backend dÃ©ployÃ© :

1. Notez l'URL : `https://ai-recommender-backend-XXXX.onrender.com`

2. Mettez Ã  jour `frontend/app.js` :
   ```javascript
   const API_URL = 'https://ai-recommender-backend-XXXX.onrender.com/api';
   ```

3. Committez et poussez :
   ```bash
   git add frontend/app.js
   git commit -m "Update API URL for production"
   git push
   ```

4. DÃ©ployez le frontend :
   - **"New +"** â†’ **"Static Site"**
   - Root Directory: `frontend`
   - Publish Directory: `.`

---

## âœ… Checklist finale

- [ ] Repository GitHub Ã  jour
- [ ] Backend crÃ©Ã© sur Render
- [ ] Build rÃ©ussi (logs verts)
- [ ] Service dÃ©marrÃ© (status healthy)
- [ ] URL backend rÃ©cupÃ©rÃ©e
- [ ] Test API avec curl/Postman
- [ ] Logs vÃ©rifiÃ©s (pas d'erreurs)

---

## ğŸ‰ Votre backend est en production !

**URL API :** `https://ai-recommender-backend-XXXX.onrender.com`

**Endpoints disponibles :**
- `GET /` - Health check
- `GET /api/stats` - Statistiques
- `GET /api/tools` - Tous les outils
- `GET /api/recommend/<tool_name>` - Recommandations
- `GET /api/search?q=<query>` - Recherche
- `GET /api/categories` - CatÃ©gories
- `GET /api/category/<category>` - Outils par catÃ©gorie

---

**Besoin d'aide ?**  
- [Documentation Render](https://render.com/docs)
- [Community Forum](https://community.render.com)
